#!/usr/bin/env python
import sys
import subprocess
from subprocess import Popen, PIPE

import logging
import torchvision
import torch
from torch.autograd import Variable

LOGGER = logging.getLogger(__name__)
logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)

def main():
    check_pytorch()

def check_pytorch():
    try:
        process = subprocess.Popen(["bash", "-c", "nvidia-smi"], stdout=PIPE)
        process.communicate()
        ret_val = process.wait()
        is_gpu = not ret_val

        if is_gpu:
            # Create a torch cuda variable
            dummy_input = Variable(torch.randn(10, 3, 224, 224)).cuda()

            assert isinstance(dummy_input, torch.Tensor), "Error: GPU sanity test for PyTorch failed."
        else:
            # Create a torch variable
            dummy_input = Variable(torch.randn(10, 3, 224, 224))

            assert isinstance(dummy_input, torch.Tensor), "Error: CPU sanity test for PyTorch failed."

    except Exception as excp:
        LOGGER.debug("Error: check_pytorch test failed.")
        LOGGER.debug("Exception: {}".format(excp))
        raise

if __name__ == "__main__":
    try:
        sys.exit(main())
    except KeyboardInterrupt:
        pass
